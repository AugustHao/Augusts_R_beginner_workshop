---
title: "Basic data cleaning and preparation in R"
author: "August Hao"
date: "26 July 2017"
output: md_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Basic data cleaning and preparation in R
## August Hao

## Problems with data?

This topic deals with scenarios in which you found your data not to be at the state you want them to be, or when R has trouble interpreting them -- so basically all the damn time. Typically, you might have problems with R misinterpreting the type and structure of your data, or you might have problems with NAs and mistakes in your data. Here we will explore some very basic ways to resolve or circumvent these problems, using the in-built base R packages. Again, this is a very complex problem and there are much better tutorials and much better tools out there to do this. If you might need to deal with massive and complicated datasets, you should consider learning about the ```dplyr``` package for data wrangling (Elise has an [amazing tutorial](https://github.com/egouldo/VicBioCon17_data_wrangling) on this, I've also linked to it in the main readme file).

### what you need to know before you start dealing with your data in R

In this topic I'm going to extensively talk about data types/structures, since there are so many potential problems around not getting them right. So if you are not sure what they are and what are the differences between types of data and structures, please take a few minutes to check out some of the introductory materials I've linked to in Readme file. For example, [RezBaz's R basics workshop ](https://nikkirubinstein.gitbooks.io/resguides-introductory-r-workshop/content/content/01-rstudio-intro.html) has really nice info and tutorials on these things.

Here I'll also explain the types and structures of data a little bit, just so you have a basic idea of what they are.

Common data types:

| Name | what they are |
|:------:|:-----:|
| Boolean (logical) | TRUE/FALSE |
| integer | 1,2,3 and so on, note that if you want to tell R a number is integer you add a capital L after it, e.g. 5L |
| numerical (double) | real numbers, 3.14 for example |
| characters | strings of letters (but numbers can be characters too), usually represented with quotation marks around them, e.g. "lol i have no idea what im doing"|

Common data structures:

| Name | what they are |
|:------:|:-----:|
| vector | literally vectors as in the mathematical definition, note that data in a vector MUST be of the same type (i.e. you can't have for example numeric and characters in the same vector) |
| matrix | a two dimensional vector basically, the same rule of data type restriction applies |
| list | main difference from a vector is entries in your list can be anything and don't have to match in type, for example your first entry could be logical and the second could be another list and so on|
| data frame | this is what you will be dealing with most of the time, under the hood a data frame is just a list of vectors with each vector representing a column in your data |

Worth to note that factors are not formally a type of data, but simply data with levels associated with them, if you don't know what factors are, please check out some of the tutorials I've linked.

## data type problems

The most common by far problem I've seen is R misinterpreting data types, especially when you important data from files generated by Excel (damn you Excel). Remember to ALWAYS check the data types of every column in your data frame when you first important them into R (you can do this by using the ```str()``` function), chances are there are some issues with it. If you see some columns are interpreted wrong, change the type by selecting the column (using ```exampledata[,column number]``` or ```exampledata$column name```), and coercing the data type using functions such as ```as.character()``` or ```as.integer()```. E.g.
```
#suppose 2nd column (called "weight" for example) in my data 'dat' is supposed to be integers but R read them as characters (misinterpreting numbers as characters is very common)
#I could use
dat[,2] <- as.integer(dat[,2])
#or
Dat$weight <- as.integer(dat$weight)
```

These sort of issues are unfortunately common, but they are not hard to fix either. A good habit to have it that, when you record data in Excel spreadsheets, try to keep data types in columns the same (i.e. all numbers no words or the other way round). If you have NA data you could also leave the cell blank instead of writing in "NA", which R will read as characters instead of actual NA. Lastly be careful of stray space bars in random cells, R will often interpret them as characters as well (and by extension R will sometimes make them levels of factors, which is really annoying).

There aren't as many common issues with data structures, because in most cases there will only be data frames. Nevertheless I would recommend not to be afraid about using other data types too, for example if you've only got 1s and 0s or TRUEs and FALSEs, a matrix will do just fine. In a similar situation if you end up writing loops or functions with complicated results, it's often a good idea to store them as lists (or vectors when you can). The reason for this is that matrices and data frame are made of columns that MUST HAVE same length, so it's a bit more work trying to set that up right. Also generally speaking converting vectors and lists to matrices or data frames is easier than the other way round.

## Factors

As mentioned before, factors are data with levels associated with them. In practice they can be used to represent categorical data, such as giraffe/elephant/zebra or male/female. It is important for many analysis, especially modelling, to have categorical data as factors. You can do so by simply using the ```factor()``` command on the column you wish to convert to factors.

However, factors can also be harder to deal with. For example, if for one column you have factors with levels: A, B, and C and you wish to add a new entry with level D; R would not do so successfully (your new entry will be NA) because D is not an existing level in the column. To be able to overcome this, you need to manually add D to the levels of the column or convert the column to characters so you can add things freely. Again, this is well covered in many tutorials, such as [RezBaz's R basics workshop ](https://nikkirubinstein.gitbooks.io/resguides-introductory-r-workshop/content/content/01-rstudio-intro.html). I won't go into too much detail on factors, but just as a general rule: it's nice to have everything in characters when you tidy your data, and only convert them to factors in the very end before your analysis.

## useful operations

You may often need to edit, clean, or restructure your data. When doing these things, it's important to remember you should not override your original raw data. As I said in earlier topics, having your untouched raw data is essential to reproducibility and it's also a very useful backup if you do something wrong. 

The workflow of editing and cleaning data is different from one case to another, but here are some general R operations that may be of use, you should look them up in R too using the ```?``` function.

* select cells, rows, or columns using ```[,]``` (first entry is row number, second for column) and ```$``` (calls for column names but not number)
* use ```dim()```, ```ncol()```, ```nrow()```, and ```length()``` to check for size of data
* ```str()``` provides a general summary of data frames
* ```head()``` and ```tail()``` return respectively the first few and last few entries of data
* ```which()``` and ```subset()``` can be used to select parts of the data that meet a particular logical statement (e.g. weight > 0.6)
* ```aggregate()``` and ```apply``` family functions can be used to transform entire columns of data or get summary statistics etc.

## should I use fancy packages for tidying data?

Base R is well equipped for tidying and preparing data, although you could do so more efficiently in ```dplyr```. I personally don't use ```dplyr``` because I'm fortunate enough to work with relatively tidy and neat data and thus have no need for it. However from my limited experiences with it I can confirm that it is indeed a better way, mainly because ```dplyr``` is just logically easier to plan out what to do.

The downside however, is that there is a learning curve with ```dplyr```, as it's style of commands and syntax is different from most R packages. ```dplyr``` is a good skillet to have if you are going to run R on daily basis, but I definitely recommend dedicating some time to learn how to use it before you start.
